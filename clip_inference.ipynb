{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from PIL import Image\n",
    "import torch\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device).eval()\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "with open(\"./data/label_rephrased_dict_cifar100.json\", \"r\") as f:\n",
    "    label_rephrased_dict = json.load(f)\n",
    "\n",
    "label_names = {\n",
    "    0: \"apple\", 1: \"aquarium_fish\", 2: \"baby\", 3: \"bear\", 4: \"beaver\", 5: \"bed\", \n",
    "    6: \"bee\", 7: \"beetle\", 8: \"bicycle\", 9: \"bottle\", 10: \"bowl\", 11: \"boy\", \n",
    "    12: \"bridge\", 13: \"bus\", 14: \"butterfly\", 15: \"camel\", 16: \"can\", 17: \"castle\", \n",
    "    18: \"caterpillar\", 19: \"cattle\", 20: \"chair\", 21: \"chimpanzee\", 22: \"clock\", \n",
    "    23: \"cloud\", 24: \"cockroach\", 25: \"couch\", 26: \"crab\", 27: \"crocodile\", \n",
    "    28: \"cup\", 29: \"dinosaur\", 30: \"dolphin\", 31: \"elephant\", 32: \"flatfish\", \n",
    "    33: \"forest\", 34: \"fox\", 35: \"girl\", 36: \"hamster\", 37: \"house\", 38: \"kangaroo\", \n",
    "    39: \"keyboard\", 40: \"lamp\", 41: \"lawn_mower\", 42: \"leopard\", 43: \"lion\", \n",
    "    44: \"lizard\", 45: \"lobster\", 46: \"man\", 47: \"maple_tree\", 48: \"motorcycle\", \n",
    "    49: \"mountain\", 50: \"mouse\", 51: \"mushroom\", 52: \"oak_tree\", 53: \"orange\", \n",
    "    54: \"orchid\", 55: \"otter\", 56: \"palm_tree\", 57: \"pear\", 58: \"pickup_truck\", \n",
    "    59: \"pine_tree\", 60: \"plain\", 61: \"plate\", 62: \"poppy\", 63: \"porcupine\", \n",
    "    64: \"possum\", 65: \"rabbit\", 66: \"raccoon\", 67: \"ray\", 68: \"road\", 69: \"rocket\", \n",
    "    70: \"rose\", 71: \"sea\", 72: \"seal\", 73: \"shark\", 74: \"shrew\", 75: \"skunk\", \n",
    "    76: \"skyscraper\", 77: \"snail\", 78: \"snake\", 79: \"spider\", 80: \"squirrel\", \n",
    "    81: \"streetcar\", 82: \"sunflower\", 83: \"sweet_pepper\", 84: \"table\", 85: \"tank\", \n",
    "    86: \"telephone\", 87: \"television\", 88: \"tiger\", 89: \"tractor\", 90: \"train\", \n",
    "    91: \"trout\", 92: \"tulip\", 93: \"turtle\", 94: \"wardrobe\", 95: \"whale\", \n",
    "    96: \"willow_tree\", 97: \"wolf\", 98: \"woman\", 99: \"worm\"\n",
    "}\n",
    "\n",
    "text_prompts_per_class = []\n",
    "for class_name in label_names.values():\n",
    "    original = f\"a photo of a {class_name}\"\n",
    "    \n",
    "    rephrased = label_rephrased_dict.get(class_name, [original] * 30)\n",
    "    prompts = [original] + rephrased\n",
    "    while len(prompts) < 31: \n",
    "        prompts.append(original)\n",
    "    text_prompts_per_class.append(prompts)\n",
    "\n",
    "text_prompts_per_variant = list(map(list, zip(*text_prompts_per_class)))\n",
    "flattened_text_inputs = [text for variant in text_prompts_per_variant for text in variant]\n",
    "\n",
    "dataset = load_from_disk(\"./cifar_100_rephrased_labels\")\n",
    "\n",
    "BATCH_SIZE = 256  # Adjust based on your GPU memory\n",
    "\n",
    "num_samples = len(dataset)\n",
    "probs_matrix = np.zeros((num_samples, 31, 100), dtype=np.float32)\n",
    "targets = np.zeros((num_samples,), dtype=np.int64)\n",
    "\n",
    "correct_predictions = {\n",
    "    'default': 0,  # For the default prompt\n",
    "    'ensemble': 0,  # For ensemble of all prompts\n",
    "    'per_variant': [0] * 31  # For each prompt variant\n",
    "}\n",
    "\n",
    "for variant_idx, text_prompts in enumerate(text_prompts_per_variant):\n",
    "    print(f\"Processing variant {variant_idx+1}/31\")\n",
    "    \n",
    "    # Process dataset in batches\n",
    "    for batch_start in tqdm(range(0, num_samples, BATCH_SIZE), desc=f\"Variant {variant_idx+1}\"):\n",
    "        batch_end = min(batch_start + BATCH_SIZE, num_samples)\n",
    "        batch_indices = list(range(batch_start, batch_end))\n",
    "        batch_size = len(batch_indices)\n",
    "        \n",
    "        # Collect batch data\n",
    "        batch_images = []\n",
    "        for idx in batch_indices:\n",
    "            example = dataset[idx]\n",
    "            image_array = example[\"img\"]\n",
    "            targets[idx] = example[\"fine_label\"]\n",
    "            batch_images.append(image_array)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Process batch of images with all text prompts\n",
    "            inputs = processor(text=text_prompts, images=batch_images, return_tensors=\"pt\", padding=True)\n",
    "            # Move inputs to the same device as the model\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits_per_image  # image-text similarity score (batch_size x num_classes)\n",
    "            probs = logits.softmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            # Store probabilities\n",
    "            for i, idx in enumerate(batch_indices):\n",
    "                probs_matrix[idx, variant_idx] = probs[i]\n",
    "                \n",
    "                # Calculate accuracy metrics (storing in memory, will calculate at the end)\n",
    "                pred_class = np.argmax(probs[i])\n",
    "                if pred_class == targets[idx]:\n",
    "                    correct_predictions['per_variant'][variant_idx] += 1\n",
    "                    \n",
    "                    # Track default prompt accuracy (first variant)\n",
    "                    if variant_idx == 0:\n",
    "                        correct_predictions['default'] += 1\n",
    "# Calculate ensemble predictions after all variants are processed\n",
    "print(\"Calculating ensemble predictions...\")\n",
    "for i in tqdm(range(num_samples), desc=\"Ensemble accuracy\"):\n",
    "    # Average predictions across all prompt variants\n",
    "    ensemble_probs = np.mean(probs_matrix[i], axis=0)\n",
    "    ensemble_pred = np.argmax(ensemble_probs)\n",
    "    if ensemble_pred == targets[i]:\n",
    "        correct_predictions['ensemble'] += 1\n",
    "\n",
    "# Calculate and print accuracy metrics\n",
    "default_accuracy = correct_predictions['default'] / num_samples\n",
    "ensemble_accuracy = correct_predictions['ensemble'] / num_samples\n",
    "variant_accuracies = [count / num_samples for count in correct_predictions['per_variant']]\n",
    "\n",
    "print(f\"Default prompt accuracy: {default_accuracy:.4f}\")\n",
    "print(f\"Ensemble prompt accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Best variant accuracy: {max(variant_accuracies):.4f} (variant {np.argmax(variant_accuracies)})\")\n",
    "print(f\"Worst variant accuracy: {min(variant_accuracies):.4f} (variant {np.argmin(variant_accuracies)})\")\n",
    "\n",
    "# Save accuracy results\n",
    "accuracy_results = {\n",
    "    'default_accuracy': float(default_accuracy),\n",
    "    'ensemble_accuracy': float(ensemble_accuracy),\n",
    "    'variant_accuracies': [float(acc) for acc in variant_accuracies],\n",
    "    'best_variant': int(np.argmax(variant_accuracies)),\n",
    "    'worst_variant': int(np.argmin(variant_accuracies))\n",
    "}\n",
    "\n",
    "with open(\"./data/clip_accuracy_results_cifar100.json\", \"w\") as f:\n",
    "    json.dump(accuracy_results, f, indent=2)\n",
    "\n",
    "# Save probability and target outputs\n",
    "np.save(\"./data/clip_probs_matrix_cifar100.npy\", probs_matrix)\n",
    "np.save(\"./data/clip_targets_cifar100.npy\", targets)\n",
    "\n",
    "print(f\"Saved results with shape: {probs_matrix.shape}, {targets.shape}\")\n",
    "print(f\"Saved accuracy results to ./data/clip_accuracy_results_cifar100.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
